{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":501,"status":"ok","timestamp":1684008458441,"user":{"displayName":"Sajjad Rezvani Khaledi","userId":"14900148791850867865"},"user_tz":-210},"id":"ci4tpH-mysUJ"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-08-11 12:05:51.049611: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2023-08-11 12:05:51.104639: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-08-11 12:05:52.036514: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]}],"source":["# import gymnasium as gym\n","import gym\n","\n","from stable_baselines3 import PPO\n","from stable_baselines3.common.vec_env import DummyVecEnv\n","from stable_baselines3.common.evaluation import evaluate_policy"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":398},"executionInfo":{"elapsed":14158,"status":"ok","timestamp":1684008472595,"user":{"displayName":"Sajjad Rezvani Khaledi","userId":"14900148791850867865"},"user_tz":-210},"id":"V0K45cCixUS_","outputId":"18bc88a6-d2d0-409d-8c37-0c254538da42"},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: setuptools==65.5.0 in /home/sajjad/.local/lib/python3.10/site-packages (65.5.0)\n","\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/setuptools/\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/setuptools/\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/setuptools/\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/setuptools/\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/setuptools/\u001b[0m\u001b[33m\n","\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","Defaulting to user installation because normal site-packages is not writeable\n","Collecting git+https://github.com/DLR-RM/stable-baselines3@feat/gymnasium-support\n","  Cloning https://github.com/DLR-RM/stable-baselines3 (to revision feat/gymnasium-support) to /tmp/pip-req-build-rzdlk0cs\n","  Running command git clone --filter=blob:none --quiet https://github.com/DLR-RM/stable-baselines3 /tmp/pip-req-build-rzdlk0cs\n","\u001b[33m  WARNING: Did not find branch or tag 'feat/gymnasium-support', assuming revision or ref.\u001b[0m\u001b[33m\n","\u001b[0m  Running command git checkout -q feat/gymnasium-support\n","  error: pathspec 'feat/gymnasium-support' did not match any file(s) known to git\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mgit checkout -q feat/gymnasium-support\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","\n","\u001b[31m×\u001b[0m \u001b[32mgit checkout -q feat/gymnasium-support\u001b[0m did not run successfully.\n","\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","\u001b[31m╰─>\u001b[0m See above for output.\n","\n","\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","Defaulting to user installation because normal site-packages is not writeable\n","Collecting git+https://github.com/Stable-Baselines-Team/stable-baselines3-contrib@feat/gymnasium-support\n","  Cloning https://github.com/Stable-Baselines-Team/stable-baselines3-contrib (to revision feat/gymnasium-support) to /tmp/pip-req-build-v54jy6li\n","  Running command git clone --filter=blob:none --quiet https://github.com/Stable-Baselines-Team/stable-baselines3-contrib /tmp/pip-req-build-v54jy6li\n","  Running command git checkout -b feat/gymnasium-support --track origin/feat/gymnasium-support\n","  Switched to a new branch 'feat/gymnasium-support'\n","  Branch 'feat/gymnasium-support' set up to track remote branch 'feat/gymnasium-support' from 'origin'.\n","  Resolved https://github.com/Stable-Baselines-Team/stable-baselines3-contrib to commit d93ca7f1a734436cee59d642fa7d3eb8b4ed0253\n","  Installing build dependencies ... \u001b[?25ldone\n","\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n","\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: stable-baselines3>=2.0.0a4 in /home/sajjad/.local/lib/python3.10/site-packages (from sb3-contrib==2.0.0a4) (2.0.0a13)\n","Requirement already satisfied: gymnasium==0.28.1 in /home/sajjad/.local/lib/python3.10/site-packages (from stable-baselines3>=2.0.0a4->sb3-contrib==2.0.0a4) (0.28.1)\n","Requirement already satisfied: numpy>=1.20 in /home/sajjad/.local/lib/python3.10/site-packages (from stable-baselines3>=2.0.0a4->sb3-contrib==2.0.0a4) (1.23.5)\n","Requirement already satisfied: torch>=1.11 in /home/sajjad/.local/lib/python3.10/site-packages (from stable-baselines3>=2.0.0a4->sb3-contrib==2.0.0a4) (2.0.1)\n","Requirement already satisfied: cloudpickle in /home/sajjad/.local/lib/python3.10/site-packages (from stable-baselines3>=2.0.0a4->sb3-contrib==2.0.0a4) (2.2.1)\n","Requirement already satisfied: pandas in /home/sajjad/.local/lib/python3.10/site-packages (from stable-baselines3>=2.0.0a4->sb3-contrib==2.0.0a4) (1.5.3)\n","Requirement already satisfied: matplotlib in /usr/lib/python3/dist-packages (from stable-baselines3>=2.0.0a4->sb3-contrib==2.0.0a4) (3.5.1)\n","Requirement already satisfied: jax-jumpy>=1.0.0 in /home/sajjad/.local/lib/python3.10/site-packages (from gymnasium==0.28.1->stable-baselines3>=2.0.0a4->sb3-contrib==2.0.0a4) (1.0.0)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /home/sajjad/.local/lib/python3.10/site-packages (from gymnasium==0.28.1->stable-baselines3>=2.0.0a4->sb3-contrib==2.0.0a4) (4.5.0)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /home/sajjad/.local/lib/python3.10/site-packages (from gymnasium==0.28.1->stable-baselines3>=2.0.0a4->sb3-contrib==2.0.0a4) (0.0.4)\n","Requirement already satisfied: filelock in /home/sajjad/.local/lib/python3.10/site-packages (from torch>=1.11->stable-baselines3>=2.0.0a4->sb3-contrib==2.0.0a4) (3.12.2)\n","Requirement already satisfied: sympy in /usr/lib/python3/dist-packages (from torch>=1.11->stable-baselines3>=2.0.0a4->sb3-contrib==2.0.0a4) (1.9)\n","Requirement already satisfied: networkx in /home/sajjad/.local/lib/python3.10/site-packages (from torch>=1.11->stable-baselines3>=2.0.0a4->sb3-contrib==2.0.0a4) (3.1)\n","Requirement already satisfied: jinja2 in /home/sajjad/.local/lib/python3.10/site-packages (from torch>=1.11->stable-baselines3>=2.0.0a4->sb3-contrib==2.0.0a4) (3.1.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/sajjad/.local/lib/python3.10/site-packages (from torch>=1.11->stable-baselines3>=2.0.0a4->sb3-contrib==2.0.0a4) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/sajjad/.local/lib/python3.10/site-packages (from torch>=1.11->stable-baselines3>=2.0.0a4->sb3-contrib==2.0.0a4) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/sajjad/.local/lib/python3.10/site-packages (from torch>=1.11->stable-baselines3>=2.0.0a4->sb3-contrib==2.0.0a4) (11.7.101)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/sajjad/.local/lib/python3.10/site-packages (from torch>=1.11->stable-baselines3>=2.0.0a4->sb3-contrib==2.0.0a4) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/sajjad/.local/lib/python3.10/site-packages (from torch>=1.11->stable-baselines3>=2.0.0a4->sb3-contrib==2.0.0a4) (11.10.3.66)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/sajjad/.local/lib/python3.10/site-packages (from torch>=1.11->stable-baselines3>=2.0.0a4->sb3-contrib==2.0.0a4) (10.9.0.58)\n","Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/sajjad/.local/lib/python3.10/site-packages (from torch>=1.11->stable-baselines3>=2.0.0a4->sb3-contrib==2.0.0a4) (10.2.10.91)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/sajjad/.local/lib/python3.10/site-packages (from torch>=1.11->stable-baselines3>=2.0.0a4->sb3-contrib==2.0.0a4) (11.4.0.1)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/sajjad/.local/lib/python3.10/site-packages (from torch>=1.11->stable-baselines3>=2.0.0a4->sb3-contrib==2.0.0a4) (11.7.4.91)\n","Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/sajjad/.local/lib/python3.10/site-packages (from torch>=1.11->stable-baselines3>=2.0.0a4->sb3-contrib==2.0.0a4) (2.14.3)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/sajjad/.local/lib/python3.10/site-packages (from torch>=1.11->stable-baselines3>=2.0.0a4->sb3-contrib==2.0.0a4) (11.7.91)\n","Requirement already satisfied: triton==2.0.0 in /home/sajjad/.local/lib/python3.10/site-packages (from torch>=1.11->stable-baselines3>=2.0.0a4->sb3-contrib==2.0.0a4) (2.0.0)\n","Requirement already satisfied: setuptools in /home/sajjad/.local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.11->stable-baselines3>=2.0.0a4->sb3-contrib==2.0.0a4) (65.5.0)\n","Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.11->stable-baselines3>=2.0.0a4->sb3-contrib==2.0.0a4) (0.37.1)\n","Requirement already satisfied: cmake in /home/sajjad/.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.11->stable-baselines3>=2.0.0a4->sb3-contrib==2.0.0a4) (3.26.4)\n","Requirement already satisfied: lit in /home/sajjad/.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.11->stable-baselines3>=2.0.0a4->sb3-contrib==2.0.0a4) (16.0.5.post0)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /home/sajjad/.local/lib/python3.10/site-packages (from pandas->stable-baselines3>=2.0.0a4->sb3-contrib==2.0.0a4) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->stable-baselines3>=2.0.0a4->sb3-contrib==2.0.0a4) (2022.1)\n","Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->stable-baselines3>=2.0.0a4->sb3-contrib==2.0.0a4) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /home/sajjad/.local/lib/python3.10/site-packages (from jinja2->torch>=1.11->stable-baselines3>=2.0.0a4->sb3-contrib==2.0.0a4) (2.1.3)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"]}],"source":["!pip install -U setuptools==65.5.0\n","!pip install git+https://github.com/DLR-RM/stable-baselines3@feat/gymnasium-support\n","!pip install git+https://github.com/Stable-Baselines-Team/stable-baselines3-contrib@feat/gymnasium-support\n","# !pip install pyglet==1.2.4\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16800,"status":"ok","timestamp":1684008522110,"user":{"displayName":"Sajjad Rezvani Khaledi","userId":"14900148791850867865"},"user_tz":-210},"id":"kGVh6xf_7R0x","outputId":"3e760bf7-d8e3-43c0-d390-f03652a288e0"},"outputs":[],"source":["# !apt-get update\n","# !apt-get install -y xvfb\n","# !Xvfb :1 -screen 0 1024x768x24 > /dev/null 2>&1 &"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1684008522111,"user":{"displayName":"Sajjad Rezvani Khaledi","userId":"14900148791850867865"},"user_tz":-210},"id":"K5r1WipuK9i1"},"outputs":[],"source":["# import os\n","# os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n","import os\n","os.environ['DISPLAY'] = ':0' "]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3841,"status":"ok","timestamp":1684008525931,"user":{"displayName":"Sajjad Rezvani Khaledi","userId":"14900148791850867865"},"user_tz":-210},"id":"Q-qqGk2LNFBJ","outputId":"d810d0c3-2363-4501-d81f-738345e6ffcd"},"outputs":[],"source":["# !pip install pygame \n","\n","# os.environ['SDL_VIDEODRIVER']='dummy'\n","# import pygame\n","# pygame.display.set_mode((640,480))\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1684008525933,"user":{"displayName":"Sajjad Rezvani Khaledi","userId":"14900148791850867865"},"user_tz":-210},"id":"fIfEV7X-L_H9"},"outputs":[],"source":["# import matplotlib.pyplot as plt\n","# %matplotlib inline\n","# from IPython import display"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3965,"status":"ok","timestamp":1684008535998,"user":{"displayName":"Sajjad Rezvani Khaledi","userId":"14900148791850867865"},"user_tz":-210},"id":"tBv6xMK51L-w","outputId":"3c4860dd-1106-4132-9d13-766911cc9cd1"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/sajjad/.local/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n","  logger.warn(\n"]},{"name":"stdout","output_type":"stream","text":["1 [ 0.17429572  1.9598557  -0.24156545 -3.0130153 ] 1.0 True False score 12.0\n","2 [-0.14530198 -0.45114872  0.22388934  0.88451236] 1.0 True False score 16.0\n","3 [ 0.17173651  0.7780909  -0.2267279  -1.4745246 ] 1.0 True False score 14.0\n","4 [ 0.08409646  0.63636386 -0.21578746 -1.199639  ] 1.0 True False score 15.0\n","5 [-0.13172458 -1.6148686   0.21875353  2.545553  ] 1.0 True False score 18.0\n","6 [ 0.12477575  1.0169717  -0.21317081 -1.6408564 ] 1.0 True False score 13.0\n","7 [-0.14606155 -0.3647769   0.21927509  0.91734797] 1.0 True False score 10.0\n","8 [ 0.17917009  0.41797954 -0.22166741 -0.8574805 ] 1.0 True False score 10.0\n","9 [-0.07163937 -0.20667636  0.22254024  1.0519133 ] 1.0 True False score 25.0\n"]}],"source":["env = gym.make( 'CartPole-v0'   , render_mode=\"human\")   \n","# state = env.reset()\n","\n","# class env(gym.Env):\n","#     def __init__(self):\n","#         ...\n","#         self.max_steps = 100\n","#         self.current_step = 0\n","\n","#     def step(self, action):\n","#         ...\n","#         self.current_step += 1\n","#         if self.current_step >= self.max_steps:\n","#             done = True\n","#         else:\n","#             done = False\n","#         return state, reward, done, info\n","\n","for episode in range(1,10):\n","    score = 0 \n","    state = env.reset()\n","    done = False \n","\n","    while not done: \n","        env.render()\n","\n","        # img = plt.imshow(env.render(mode='rgb_array'))\n","        # img.set_data(env.render(mode= 'rgb_array'))\n","        # display.display(plt.gcf())    \n","        # display.clear_output(wait=True)\n","\n","        action = env.action_space.sample()\n","        state , reward , done , info , _ = env.step(action)\n","        score += reward \n","\n","    print( episode ,state , reward , done , info , 'score',  score)\n","env.close()"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: shimmy>=0.2.1 in /home/sajjad/.local/lib/python3.10/site-packages (1.1.0)\n","Requirement already satisfied: numpy>=1.18.0 in /home/sajjad/.local/lib/python3.10/site-packages (from shimmy>=0.2.1) (1.23.5)\n","Requirement already satisfied: gymnasium>=0.27.0 in /home/sajjad/.local/lib/python3.10/site-packages (from shimmy>=0.2.1) (0.28.1)\n","Requirement already satisfied: jax-jumpy>=1.0.0 in /home/sajjad/.local/lib/python3.10/site-packages (from gymnasium>=0.27.0->shimmy>=0.2.1) (1.0.0)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /home/sajjad/.local/lib/python3.10/site-packages (from gymnasium>=0.27.0->shimmy>=0.2.1) (2.2.1)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /home/sajjad/.local/lib/python3.10/site-packages (from gymnasium>=0.27.0->shimmy>=0.2.1) (4.5.0)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /home/sajjad/.local/lib/python3.10/site-packages (from gymnasium>=0.27.0->shimmy>=0.2.1) (0.0.4)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"]}],"source":["!pip install 'shimmy>=0.2.1'"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":432},"executionInfo":{"elapsed":10161,"status":"error","timestamp":1684008550218,"user":{"displayName":"Sajjad Rezvani Khaledi","userId":"14900148791850867865"},"user_tz":-210},"id":"-bAnlPLW2D6o","outputId":"17928506-7528-45bc-99c8-3bb0d837fb93"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using cpu device\n","-----------------------------\n","| time/              |      |\n","|    fps             | 47   |\n","|    iterations      | 1    |\n","|    time_elapsed    | 43   |\n","|    total_timesteps | 2048 |\n","-----------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 47         |\n","|    iterations           | 2          |\n","|    time_elapsed         | 86         |\n","|    total_timesteps      | 4096       |\n","| train/                  |            |\n","|    approx_kl            | 0.00863597 |\n","|    clip_fraction        | 0.0818     |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -0.686     |\n","|    explained_variance   | 0.00398    |\n","|    learning_rate        | 0.0003     |\n","|    loss                 | 7.3        |\n","|    n_updates            | 10         |\n","|    policy_gradient_loss | -0.0118    |\n","|    value_loss           | 47.7       |\n","----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 47          |\n","|    iterations           | 3           |\n","|    time_elapsed         | 129         |\n","|    total_timesteps      | 6144        |\n","| train/                  |             |\n","|    approx_kl            | 0.009617484 |\n","|    clip_fraction        | 0.0665      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.666      |\n","|    explained_variance   | 0.0896      |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 10.4        |\n","|    n_updates            | 20          |\n","|    policy_gradient_loss | -0.0189     |\n","|    value_loss           | 35.7        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 47          |\n","|    iterations           | 4           |\n","|    time_elapsed         | 172         |\n","|    total_timesteps      | 8192        |\n","| train/                  |             |\n","|    approx_kl            | 0.009083781 |\n","|    clip_fraction        | 0.11        |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.628      |\n","|    explained_variance   | 0.22        |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 20.9        |\n","|    n_updates            | 30          |\n","|    policy_gradient_loss | -0.0232     |\n","|    value_loss           | 48.8        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 47          |\n","|    iterations           | 5           |\n","|    time_elapsed         | 214         |\n","|    total_timesteps      | 10240       |\n","| train/                  |             |\n","|    approx_kl            | 0.008197928 |\n","|    clip_fraction        | 0.0761      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.613      |\n","|    explained_variance   | 0.302       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 21.3        |\n","|    n_updates            | 40          |\n","|    policy_gradient_loss | -0.017      |\n","|    value_loss           | 60          |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 47          |\n","|    iterations           | 6           |\n","|    time_elapsed         | 256         |\n","|    total_timesteps      | 12288       |\n","| train/                  |             |\n","|    approx_kl            | 0.008642744 |\n","|    clip_fraction        | 0.0958      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.594      |\n","|    explained_variance   | 0.376       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 38.8        |\n","|    n_updates            | 50          |\n","|    policy_gradient_loss | -0.0166     |\n","|    value_loss           | 66.6        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 47          |\n","|    iterations           | 7           |\n","|    time_elapsed         | 298         |\n","|    total_timesteps      | 14336       |\n","| train/                  |             |\n","|    approx_kl            | 0.008176904 |\n","|    clip_fraction        | 0.0898      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.601      |\n","|    explained_variance   | 0.612       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 13.8        |\n","|    n_updates            | 60          |\n","|    policy_gradient_loss | -0.0127     |\n","|    value_loss           | 47.9        |\n","-----------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 48           |\n","|    iterations           | 8            |\n","|    time_elapsed         | 340          |\n","|    total_timesteps      | 16384        |\n","| train/                  |              |\n","|    approx_kl            | 0.0031733722 |\n","|    clip_fraction        | 0.0296       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.572       |\n","|    explained_variance   | 0.357        |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 41.1         |\n","|    n_updates            | 70           |\n","|    policy_gradient_loss | -0.00643     |\n","|    value_loss           | 56.6         |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 48           |\n","|    iterations           | 9            |\n","|    time_elapsed         | 383          |\n","|    total_timesteps      | 18432        |\n","| train/                  |              |\n","|    approx_kl            | 0.0049755117 |\n","|    clip_fraction        | 0.0359       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.556       |\n","|    explained_variance   | 0.212        |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 38.6         |\n","|    n_updates            | 80           |\n","|    policy_gradient_loss | -0.00811     |\n","|    value_loss           | 71.5         |\n","------------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 48          |\n","|    iterations           | 10          |\n","|    time_elapsed         | 425         |\n","|    total_timesteps      | 20480       |\n","| train/                  |             |\n","|    approx_kl            | 0.008620048 |\n","|    clip_fraction        | 0.103       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.574      |\n","|    explained_variance   | 0.867       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 3.52        |\n","|    n_updates            | 90          |\n","|    policy_gradient_loss | -0.0141     |\n","|    value_loss           | 21.6        |\n","-----------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 48           |\n","|    iterations           | 11           |\n","|    time_elapsed         | 467          |\n","|    total_timesteps      | 22528        |\n","| train/                  |              |\n","|    approx_kl            | 0.0032370235 |\n","|    clip_fraction        | 0.0155       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.556       |\n","|    explained_variance   | 0.709        |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 2.61         |\n","|    n_updates            | 100          |\n","|    policy_gradient_loss | -0.00297     |\n","|    value_loss           | 20.4         |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 48           |\n","|    iterations           | 12           |\n","|    time_elapsed         | 509          |\n","|    total_timesteps      | 24576        |\n","| train/                  |              |\n","|    approx_kl            | 0.0041751317 |\n","|    clip_fraction        | 0.0319       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.561       |\n","|    explained_variance   | 0.889        |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 0.658        |\n","|    n_updates            | 110          |\n","|    policy_gradient_loss | -0.0052      |\n","|    value_loss           | 7.25         |\n","------------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 48          |\n","|    iterations           | 13          |\n","|    time_elapsed         | 551         |\n","|    total_timesteps      | 26624       |\n","| train/                  |             |\n","|    approx_kl            | 0.001967896 |\n","|    clip_fraction        | 0.0252      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.54       |\n","|    explained_variance   | 0.00679     |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 2.12        |\n","|    n_updates            | 120         |\n","|    policy_gradient_loss | -0.00415    |\n","|    value_loss           | 44.4        |\n","-----------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 48           |\n","|    iterations           | 14           |\n","|    time_elapsed         | 593          |\n","|    total_timesteps      | 28672        |\n","| train/                  |              |\n","|    approx_kl            | 0.0058930884 |\n","|    clip_fraction        | 0.03         |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.53        |\n","|    explained_variance   | 0.156        |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 6.66         |\n","|    n_updates            | 130          |\n","|    policy_gradient_loss | -0.00537     |\n","|    value_loss           | 21.3         |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 48           |\n","|    iterations           | 15           |\n","|    time_elapsed         | 635          |\n","|    total_timesteps      | 30720        |\n","| train/                  |              |\n","|    approx_kl            | 0.0022062464 |\n","|    clip_fraction        | 0.0187       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.52        |\n","|    explained_variance   | 0.314        |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 0.399        |\n","|    n_updates            | 140          |\n","|    policy_gradient_loss | -0.00104     |\n","|    value_loss           | 2.17         |\n","------------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 48         |\n","|    iterations           | 16         |\n","|    time_elapsed         | 677        |\n","|    total_timesteps      | 32768      |\n","| train/                  |            |\n","|    approx_kl            | 0.00479266 |\n","|    clip_fraction        | 0.0259     |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -0.52      |\n","|    explained_variance   | 0.421      |\n","|    learning_rate        | 0.0003     |\n","|    loss                 | 0.117      |\n","|    n_updates            | 150        |\n","|    policy_gradient_loss | -0.00112   |\n","|    value_loss           | 1.4        |\n","----------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 48           |\n","|    iterations           | 17           |\n","|    time_elapsed         | 719          |\n","|    total_timesteps      | 34816        |\n","| train/                  |              |\n","|    approx_kl            | 0.0020839623 |\n","|    clip_fraction        | 0.00742      |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.521       |\n","|    explained_variance   | 0.202        |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 0.088        |\n","|    n_updates            | 160          |\n","|    policy_gradient_loss | -0.000294    |\n","|    value_loss           | 0.994        |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 48           |\n","|    iterations           | 18           |\n","|    time_elapsed         | 761          |\n","|    total_timesteps      | 36864        |\n","| train/                  |              |\n","|    approx_kl            | 0.0006452719 |\n","|    clip_fraction        | 0.000537     |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.515       |\n","|    explained_variance   | 0.1          |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 3.82         |\n","|    n_updates            | 170          |\n","|    policy_gradient_loss | -0.00195     |\n","|    value_loss           | 26           |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 48           |\n","|    iterations           | 19           |\n","|    time_elapsed         | 804          |\n","|    total_timesteps      | 38912        |\n","| train/                  |              |\n","|    approx_kl            | 0.0045444034 |\n","|    clip_fraction        | 0.0369       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.495       |\n","|    explained_variance   | -0.214       |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 0.072        |\n","|    n_updates            | 180          |\n","|    policy_gradient_loss | -0.00223     |\n","|    value_loss           | 0.464        |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 48           |\n","|    iterations           | 20           |\n","|    time_elapsed         | 846          |\n","|    total_timesteps      | 40960        |\n","| train/                  |              |\n","|    approx_kl            | 0.0071010096 |\n","|    clip_fraction        | 0.0754       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.479       |\n","|    explained_variance   | 0.675        |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 0.0606       |\n","|    n_updates            | 190          |\n","|    policy_gradient_loss | -0.00809     |\n","|    value_loss           | 0.294        |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 48           |\n","|    iterations           | 21           |\n","|    time_elapsed         | 888          |\n","|    total_timesteps      | 43008        |\n","| train/                  |              |\n","|    approx_kl            | 0.0036463116 |\n","|    clip_fraction        | 0.0338       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.475       |\n","|    explained_variance   | 0.305        |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 0.0502       |\n","|    n_updates            | 200          |\n","|    policy_gradient_loss | -0.00539     |\n","|    value_loss           | 0.188        |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 48           |\n","|    iterations           | 22           |\n","|    time_elapsed         | 930          |\n","|    total_timesteps      | 45056        |\n","| train/                  |              |\n","|    approx_kl            | 0.0045631677 |\n","|    clip_fraction        | 0.0382       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.477       |\n","|    explained_variance   | 0.0338       |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 0.0469       |\n","|    n_updates            | 210          |\n","|    policy_gradient_loss | -0.00189     |\n","|    value_loss           | 0.115        |\n","------------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 48          |\n","|    iterations           | 23          |\n","|    time_elapsed         | 972         |\n","|    total_timesteps      | 47104       |\n","| train/                  |             |\n","|    approx_kl            | 0.002889195 |\n","|    clip_fraction        | 0.00952     |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.476      |\n","|    explained_variance   | -0.0281     |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 0.00438     |\n","|    n_updates            | 220         |\n","|    policy_gradient_loss | 0.000148    |\n","|    value_loss           | 0.0729      |\n","-----------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 48           |\n","|    iterations           | 24           |\n","|    time_elapsed         | 1014         |\n","|    total_timesteps      | 49152        |\n","| train/                  |              |\n","|    approx_kl            | 0.0021852478 |\n","|    clip_fraction        | 0.0152       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.473       |\n","|    explained_variance   | -0.0952      |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | -0.00929     |\n","|    n_updates            | 230          |\n","|    policy_gradient_loss | -0.000704    |\n","|    value_loss           | 0.0501       |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 48           |\n","|    iterations           | 25           |\n","|    time_elapsed         | 1056         |\n","|    total_timesteps      | 51200        |\n","| train/                  |              |\n","|    approx_kl            | 0.0021761977 |\n","|    clip_fraction        | 0.013        |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.478       |\n","|    explained_variance   | -0.0267      |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 0.00049      |\n","|    n_updates            | 240          |\n","|    policy_gradient_loss | -0.001       |\n","|    value_loss           | 0.0324       |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 48           |\n","|    iterations           | 26           |\n","|    time_elapsed         | 1098         |\n","|    total_timesteps      | 53248        |\n","| train/                  |              |\n","|    approx_kl            | 0.0036577347 |\n","|    clip_fraction        | 0.0132       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.456       |\n","|    explained_variance   | -0.00172     |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 0.00332      |\n","|    n_updates            | 250          |\n","|    policy_gradient_loss | -0.000613    |\n","|    value_loss           | 0.0214       |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 48           |\n","|    iterations           | 27           |\n","|    time_elapsed         | 1140         |\n","|    total_timesteps      | 55296        |\n","| train/                  |              |\n","|    approx_kl            | 0.0032756578 |\n","|    clip_fraction        | 0.0226       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.456       |\n","|    explained_variance   | -0.0771      |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 0.0191       |\n","|    n_updates            | 260          |\n","|    policy_gradient_loss | -0.000729    |\n","|    value_loss           | 0.0148       |\n","------------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 48         |\n","|    iterations           | 28         |\n","|    time_elapsed         | 1182       |\n","|    total_timesteps      | 57344      |\n","| train/                  |            |\n","|    approx_kl            | 0.00380745 |\n","|    clip_fraction        | 0.0265     |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -0.442     |\n","|    explained_variance   | -0.0681    |\n","|    learning_rate        | 0.0003     |\n","|    loss                 | -0.00546   |\n","|    n_updates            | 270        |\n","|    policy_gradient_loss | -0.0012    |\n","|    value_loss           | 0.00991    |\n","----------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 48           |\n","|    iterations           | 29           |\n","|    time_elapsed         | 1224         |\n","|    total_timesteps      | 59392        |\n","| train/                  |              |\n","|    approx_kl            | 0.0047251633 |\n","|    clip_fraction        | 0.0347       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.434       |\n","|    explained_variance   | -0.0259      |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | -0.00518     |\n","|    n_updates            | 280          |\n","|    policy_gradient_loss | -0.00241     |\n","|    value_loss           | 0.00703      |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 48           |\n","|    iterations           | 30           |\n","|    time_elapsed         | 1266         |\n","|    total_timesteps      | 61440        |\n","| train/                  |              |\n","|    approx_kl            | 0.0052531348 |\n","|    clip_fraction        | 0.0481       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.446       |\n","|    explained_variance   | -0.0549      |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 0.0207       |\n","|    n_updates            | 290          |\n","|    policy_gradient_loss | -0.00218     |\n","|    value_loss           | 0.00499      |\n","------------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 48          |\n","|    iterations           | 31          |\n","|    time_elapsed         | 1308        |\n","|    total_timesteps      | 63488       |\n","| train/                  |             |\n","|    approx_kl            | 0.003511634 |\n","|    clip_fraction        | 0.0143      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.446      |\n","|    explained_variance   | -0.105      |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 0.0164      |\n","|    n_updates            | 300         |\n","|    policy_gradient_loss | -0.000336   |\n","|    value_loss           | 0.00341     |\n","-----------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 48           |\n","|    iterations           | 32           |\n","|    time_elapsed         | 1351         |\n","|    total_timesteps      | 65536        |\n","| train/                  |              |\n","|    approx_kl            | 0.0030791361 |\n","|    clip_fraction        | 0.0292       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.459       |\n","|    explained_variance   | -0.0289      |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | -0.00485     |\n","|    n_updates            | 310          |\n","|    policy_gradient_loss | -0.00213     |\n","|    value_loss           | 0.00235      |\n","------------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 48          |\n","|    iterations           | 33          |\n","|    time_elapsed         | 1393        |\n","|    total_timesteps      | 67584       |\n","| train/                  |             |\n","|    approx_kl            | 0.005058011 |\n","|    clip_fraction        | 0.0422      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.459      |\n","|    explained_variance   | -0.107      |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | -0.00583    |\n","|    n_updates            | 320         |\n","|    policy_gradient_loss | -0.00217    |\n","|    value_loss           | 0.00167     |\n","-----------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 48           |\n","|    iterations           | 34           |\n","|    time_elapsed         | 1435         |\n","|    total_timesteps      | 69632        |\n","| train/                  |              |\n","|    approx_kl            | 0.0044257836 |\n","|    clip_fraction        | 0.0413       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.457       |\n","|    explained_variance   | -0.099       |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 0.00507      |\n","|    n_updates            | 330          |\n","|    policy_gradient_loss | -0.00303     |\n","|    value_loss           | 0.00119      |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 48           |\n","|    iterations           | 35           |\n","|    time_elapsed         | 1477         |\n","|    total_timesteps      | 71680        |\n","| train/                  |              |\n","|    approx_kl            | 0.0034165788 |\n","|    clip_fraction        | 0.0528       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.462       |\n","|    explained_variance   | -0.134       |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 0.00437      |\n","|    n_updates            | 340          |\n","|    policy_gradient_loss | -0.00352     |\n","|    value_loss           | 0.000846     |\n","------------------------------------------\n"]}],"source":["env = gym.make( 'CartPole-v0' , render_mode = 'human')\n","env = DummyVecEnv( [lambda: env ])\n","\n","model = PPO( 'MlpPolicy' , env , verbose=1  )\n","model.learn( total_timesteps = 70000)\n","\n","model.save('ppo_model')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"aborted","timestamp":1684008550219,"user":{"displayName":"Sajjad Rezvani Khaledi","userId":"14900148791850867865"},"user_tz":-210},"id":"oE1Et_aBW2jr"},"outputs":[],"source":["# evaluate_policy( model , env , n_eval_episodes=100 , render='Human' )\n","# env.close()"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1 [-0.07163937 -0.20667636  0.22254024  1.0519133 ] 1.0 False True score 1000.0\n","2 [-0.07163937 -0.20667636  0.22254024  1.0519133 ] 1.0 False True score 1000.0\n","3 [-0.07163937 -0.20667636  0.22254024  1.0519133 ] 1.0 False True score 1000.0\n","4 [-0.07163937 -0.20667636  0.22254024  1.0519133 ] 1.0 False True score 1000.0\n","5 [-0.07163937 -0.20667636  0.22254024  1.0519133 ] 1.0 False True score 1000.0\n","6 [-0.07163937 -0.20667636  0.22254024  1.0519133 ] 1.0 False True score 1000.0\n","7 [-0.07163937 -0.20667636  0.22254024  1.0519133 ] 1.0 False True score 1000.0\n","8 [-0.07163937 -0.20667636  0.22254024  1.0519133 ] 1.0 False True score 1000.0\n","9 [-0.07163937 -0.20667636  0.22254024  1.0519133 ] 1.0 False True score 1000.0\n","10 [-0.07163937 -0.20667636  0.22254024  1.0519133 ] 1.0 False True score 1000.0\n","11 [-0.07163937 -0.20667636  0.22254024  1.0519133 ] 1.0 False True score 1000.0\n","12 [-0.07163937 -0.20667636  0.22254024  1.0519133 ] 1.0 False True score 1000.0\n","13 [-0.07163937 -0.20667636  0.22254024  1.0519133 ] 1.0 False True score 1000.0\n","14 [-0.07163937 -0.20667636  0.22254024  1.0519133 ] 1.0 False True score 1000.0\n","15 [-0.07163937 -0.20667636  0.22254024  1.0519133 ] 1.0 False True score 1000.0\n","16 [-0.07163937 -0.20667636  0.22254024  1.0519133 ] 1.0 False True score 1000.0\n","17 [-0.07163937 -0.20667636  0.22254024  1.0519133 ] 1.0 False True score 1000.0\n","18 [-0.07163937 -0.20667636  0.22254024  1.0519133 ] 1.0 False True score 1000.0\n","19 [-0.07163937 -0.20667636  0.22254024  1.0519133 ] 1.0 False True score 1000.0\n","20 [-0.07163937 -0.20667636  0.22254024  1.0519133 ] 1.0 False True score 1000.0\n","21 [-0.07163937 -0.20667636  0.22254024  1.0519133 ] 1.0 False True score 1000.0\n","22 [-0.07163937 -0.20667636  0.22254024  1.0519133 ] 1.0 False True score 1000.0\n","23 [-0.07163937 -0.20667636  0.22254024  1.0519133 ] 1.0 False True score 1000.0\n","24 [-0.07163937 -0.20667636  0.22254024  1.0519133 ] 1.0 False True score 1000.0\n","25 [-0.07163937 -0.20667636  0.22254024  1.0519133 ] 1.0 False True score 1000.0\n","26 [-0.07163937 -0.20667636  0.22254024  1.0519133 ] 1.0 False True score 1000.0\n","27 [-0.07163937 -0.20667636  0.22254024  1.0519133 ] 1.0 False True score 1000.0\n","28 [-0.07163937 -0.20667636  0.22254024  1.0519133 ] 1.0 False True score 1000.0\n","29 [-0.07163937 -0.20667636  0.22254024  1.0519133 ] 1.0 False True score 1000.0\n"]}],"source":["env = gym.make( 'CartPole-v1'  , render_mode = 'human' )   \n","\n","\n","max = 1000\n","for episode in range(1,30):\n","    score = 0 \n","    obs , _ = env.reset()\n","    done = False \n","    epoch = 0\n","\n","    while not done and epoch<max: \n","        env.render()\n","        action , _ = model.predict(obs)\n","        obs , reward , done , info, _ = env.step(action)\n","        score += reward \n","        epoch +=1\n","        # print(epoch)\n","\n","    print( episode ,state , reward , done , info , 'score',  score)\n","env.close()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["----------------------\n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: onnx in /home/sajjad/.local/lib/python3.10/site-packages (1.14.0)\n","Requirement already satisfied: numpy in /home/sajjad/.local/lib/python3.10/site-packages (from onnx) (1.23.5)\n","Requirement already satisfied: protobuf>=3.20.2 in /home/sajjad/.local/lib/python3.10/site-packages (from onnx) (4.23.3)\n","Requirement already satisfied: typing-extensions>=3.6.2.1 in /home/sajjad/.local/lib/python3.10/site-packages (from onnx) (4.5.0)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"]}],"source":["!pip install onnx"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n","verbose: False, log level: Level.ERROR\n","======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n","\n"]}],"source":["import onnx\n","import torch as th\n","\n","class OnnxablePolicy(th.nn.Module):\n","    def __init__(self, extractor, action_net, value_net):\n","        super().__init__()\n","        self.extractor = extractor\n","        self.action_net = action_net\n","        self.value_net = value_net\n","\n","    def forward(self, observation):\n","        # NOTE: You may have to process (normalize) observation in the correct\n","        #       way before using this. See `common.preprocessing.preprocess_obs`\n","        action_hidden, value_hidden = self.extractor(observation)\n","        return self.action_net(action_hidden), self.value_net(value_hidden)\n","\n","\n","\n","model = PPO.load(\"ppo_model.zip\", device=\"cpu\")\n","onnxable_model = OnnxablePolicy(\n","    model.policy.mlp_extractor, model.policy.action_net, model.policy.value_net\n",")\n","\n","observation_size = model.observation_space.shape\n","dummy_input = th.randn(1, *observation_size)\n","th.onnx.export(\n","    onnxable_model,\n","    dummy_input,\n","    \"my_ppo_model.onnx\",\n","    opset_version=9,\n","    input_names=[\"input\"],\n",")"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["learning episode: 0\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","learning episode: 1\n","1/1 [==============================] - 0s 48ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 21ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 20ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 19ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 18ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 25ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 21ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","learning episode: 2\n","1/1 [==============================] - 0s 17ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 27ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 20ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 28ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 24ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 19ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 18ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","learning episode: 3\n","1/1 [==============================] - 0s 21ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 22ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 20ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 19ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 18ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 36ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 24ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 18ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 22ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","learning episode: 4\n","1/1 [==============================] - 0s 22ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 19ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 22ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 19ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 22ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 25ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 18ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 19ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 22ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 30ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","learning episode: 5\n","1/1 [==============================] - 0s 21ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 21ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 18ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 22ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 19ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 20ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 19ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 20ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 21ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","learning episode: 6\n","1/1 [==============================] - 0s 19ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 20ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 31ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 19ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 17ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 18ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 17ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 17ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 22ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","learning episode: 7\n","1/1 [==============================] - 0s 18ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n","1/1 [==============================] - 0s 21ms/step\n","\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated: 1.0\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[33], line 141\u001b[0m\n\u001b[1;32m    139\u001b[0m num_episodes \u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[1;32m    140\u001b[0m deepQ_object \u001b[39m=\u001b[39m DQL( env, gamma, epsilon, num_episodes)\n\u001b[0;32m--> 141\u001b[0m deepQ_object\u001b[39m.\u001b[39;49mtraining_episodes()\n\u001b[1;32m    142\u001b[0m \u001b[39mprint\u001b[39m( deepQ_object\u001b[39m.\u001b[39msum_rewards_episode )\n\u001b[1;32m    143\u001b[0m \u001b[39mprint\u001b[39m( deepQ_object\u001b[39m.\u001b[39mmain_network\u001b[39m.\u001b[39msummary() )\n","Cell \u001b[0;32mIn[33], line 65\u001b[0m, in \u001b[0;36mDQL.training_episodes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m terminal_state \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m terminal_state:   \n\u001b[0;32m---> 65\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mrender()\n\u001b[1;32m     67\u001b[0m     action \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mselectAction( current_state, index_episode)\n\u001b[1;32m     68\u001b[0m     (next_state, reward, terminal_state, _ , _ ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mstep(action)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/gym/core.py:329\u001b[0m, in \u001b[0;36mWrapper.render\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrender\u001b[39m(\n\u001b[1;32m    326\u001b[0m     \u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    327\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[Union[RenderFrame, List[RenderFrame]]]:\n\u001b[1;32m    328\u001b[0m     \u001b[39m\"\"\"Renders the environment.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 329\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mrender(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/gym/wrappers/order_enforcing.py:51\u001b[0m, in \u001b[0;36mOrderEnforcing.render\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_disable_render_order_enforcing \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_reset:\n\u001b[1;32m     47\u001b[0m     \u001b[39mraise\u001b[39;00m ResetNeeded(\n\u001b[1;32m     48\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot call `env.render()` before calling `env.reset()`, if this is a intended action, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     49\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mset `disable_render_order_enforcing=True` on the OrderEnforcer wrapper.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     50\u001b[0m     )\n\u001b[0;32m---> 51\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mrender(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/gym/wrappers/env_checker.py:55\u001b[0m, in \u001b[0;36mPassiveEnvChecker.render\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[39mreturn\u001b[39;00m env_render_passive_checker(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     54\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 55\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mrender(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/gym/envs/classic_control/cartpole.py:298\u001b[0m, in \u001b[0;36mCartPoleEnv.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrender_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    297\u001b[0m     pygame\u001b[39m.\u001b[39mevent\u001b[39m.\u001b[39mpump()\n\u001b[0;32m--> 298\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclock\u001b[39m.\u001b[39;49mtick(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmetadata[\u001b[39m\"\u001b[39;49m\u001b[39mrender_fps\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m    299\u001b[0m     pygame\u001b[39m.\u001b[39mdisplay\u001b[39m.\u001b[39mflip()\n\u001b[1;32m    301\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrender_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrgb_array\u001b[39m\u001b[39m\"\u001b[39m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# import keras \n","import numpy as np \n","import random \n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import RMSprop\n","from collections import deque\n","from tensorflow import gather_nd \n","from tensorflow.keras.losses import mean_squared_error\n","# import keras2onnx\n","import onnx\n","class DQL():\n","    def __init__(self, env, gamma, epsilon, num_episodes):\n","        self.env = env \n","        self.gamma = gamma\n","        self.epsilon= epsilon\n","        self.num_episodes= num_episodes\n","        # dimension: \n","        self.state_dimension = 4\n","        # actions\n","        self.action_dimension = 2 \n","        # max size of replay buffer\n","        self.replay_buffer_size = 300\n","        # size of training batch sampled from replay buffer\n","        self.batch_replay_buffer_size = 100\n","        # update tershold and update counter \n","        self.update_target_network_tershold= 100\n","        self.counter_update_target_network= 0       \n","        self.sum_rewards_episode= []\n","        self.replay_buffer = deque( maxlen=self.replay_buffer_size)\n","        self.main_network = self.creat_network()       \n","        self.target_network = self.creat_network()\n","        self.target_network.set_weights( self.main_network.get_weights() )\n","        # this list is used in the cost function to select certain entries of the \n","        # predicted and true sample matrices in order to form the loss\n","        self.action_list =[]\n","    def creat_network(self):\n","        model = Sequential()\n","        model.add( Dense(128, input_dim=self.state_dimension, activation= 'relu') )\n","        model.add( Dense(56, activation= 'relu') )\n","        model.add( Dense(self.action_dimension, activation= 'linear') )\n","        model.compile( optimizer=RMSprop(), loss = self.custom_loss, metrics=['accuracy'] )       \n","        return model\n","    # the selection is performed on the basis of the action indices in the list  self.actionsAppend\n","    def custom_loss( self, y_true, y_pred):\n","        s1,s2 = y_true.shape\n","        # size = self.batch_replay_buffer_size , 2\n","        indices= np.zeros( shape=(s1,s2))\n","        indices[:,0]= np.arange(s1)\n","        indices[:,1]= self.action_list\n","        # extract slices from a tensor by specifying the indices of the elements you want to retrieve.\n","        loss = mean_squared_error( gather_nd(y_true, indices=indices.astype(int)) /\n","                                   gather_nd(y_pred, indices=indices.astype(int)) )\n","        return loss\n","    #main training function\n","    def training_episodes(self):        \n","        for index_episode in range(self.num_episodes):            \n","            # list of error per episode \n","            reward_episode = []\n","\n","            print('learning episode:',index_episode)\n","            (current_state , _ ) = self.env.reset()\n","            terminal_state = False\n","            while not terminal_state:   \n","                self.env.render()\n","\n","                action = self.selectAction( current_state, index_episode)\n","                (next_state, reward, terminal_state, _ , _ ) = self.env.step(action)\n","                reward_episode.append(reward)\n","                print('\\n>>>>>>>>>>>>>>>>>>>>>>>>>>>>terminated:', reward)\n","\n","                self.replay_buffer.append( (current_state, action, reward, next_state, terminal_state))\n","                self.train_network()           \n","        return \n","    def selectAction(self, state, index):       \n","        #firstly just explore\n","        if index < 1: \n","            return np.random.choice( self.action_dimension)    \n","                 \n","        random_sample = np.random.random()\n","        # move from explore to exploit \n","        if index>200: \n","            self.epsilon = 0.999*self.epsilon\n","        # exploration\n","        if random_sample < self.epsilon:\n","            return np.random.choice( self.action_dimension)       \n","        #exploitation\n","        else: \n","            qValues = self.main_network.predict( state.reshape(1,4) )\n","            #choose randomly between all max values of qValues\n","            return np.random.choice( np.where(qValues[0,:]==np.max(qValues[0,:]))[0] )\n","    def train_network(self):       \n","     \n","        # is replay buffer full?\n","        if( len(self.replay_buffer)> self.batch_replay_buffer_size) :\n","            current_state_batch = np.zeros( shape=(self.batch_replay_buffer_size ,4))\n","            next_state_batch = np.zeros( shape=(self.batch_replay_buffer_size, 4)) \n","            #sample a batch from replay buffer \n","            random_sample_batch = random.sample(self.replay_buffer , self.batch_replay_buffer_size)\n","\n","            for index, tuples in enumerate(random_sample_batch):\n","                #prepare input of network \n","                current_state_batch[index, :] = tuples[0]\n","                next_state_batch[index, :] = tuples[3]\n","\n","            #calculate the values of current and next states by main and target network\n","            Qnext_target_network = self.target_network.predict(next_state_batch)\n","            Qcurrent_main_network = self.main_network.predict(current_state_batch)\n","            # in & out network for training \n","            input_network = current_state_batch\n","            output_network = np.zeros( shape=(self.batch_replay_buffer_size,2 ))\n","            self.action_list= []\n","\n","            for index, (current_state, action, reward, next_state, teminated) in enumerate(random_sample_batch):\n","                if teminated:\n","                    y = reward\n","                else:         # Bellman equation \n","                    y = reward + self.gamma*np.max(Qnext_target_network[index])\n","                self.action_list.append(action)\n","                #prepare output of network from calculate return of every action in every state\n","                output_network[index] = Qcurrent_main_network[index]\n","                output_network[index, action] = y\n","\n","            # learning process of main network\n","            self.main_network.fit( input_network, output_network, batch_size= self.batch_replay_buffer_size, verbose=0, epochs=0)\n","            # target net counter plus\n","            self.counter_update_target_network+=1\n","            #soft update of target network \n","            if (self.counter_update_target_network >= self.update_target_network_tershold):\n","                self.target_network.set_weights( self.main_network.get_weights() )\n","                print( \"target updated --- counter value: \" , self.counter_update_target_network)\n","                #target net counter reset \n","                self.counter_update_target_network =0 \n","import gym\n","env= gym.make( 'CartPole-v1' , render_mode=\"human\")\n","gamma = 1\n","# epsilon greedy\n","epsilon = 0.1\n","num_episodes = 1000\n","deepQ_object = DQL( env, gamma, epsilon, num_episodes)\n","deepQ_object.training_episodes()\n","print( deepQ_object.sum_rewards_episode )\n","print( deepQ_object.main_network.summary() )\n","deepQ_object.main_network.save('deepQ_network_model.h5')\n","\n","########## convert model to ONNX\n","# onnx_model = keras2onnx.convert_keras(deepQ_object,         # keras model\n","#                          name=\"example\",           # the converted ONNX model internal name                     \n","#                          target_opset=9,           # the ONNX version to export the model to\n","#                          channel_first_inputs=None # which inputs to transpose from NHWC to NCHW\n","#                          )\n","# onnx.save_model(onnx_model, \"example.onnx\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":0}
